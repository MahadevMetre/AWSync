part 1:,
part 2 in next message, because it says message too long!

# tactiq.io free youtube transcript
# PYTHON PROJECT FOR DEVOPS| ADD THIS TO YOUR RESUME| AWS NINJA | #aws #devops #python | Python DevOps
# AWSync youtube video
# part 1: https://www.youtube.com/watch?v=ybbQW6cLKEQ
# part 2: https://www.youtube.com/watch?v=DgavixR_w5Y
# GitHub Link: https://github.com/iam-veeramalla/devops-project-ideas/tree/main/python/aws/Ninja


# Code:
# ppt : https://gamma.app/docs/AWSync-Project-0hj24t3k6olq7ts
hello everyone my name is Abhishek and
welcome back to my channel after the
last video on shell scripting project
for devops engineers I have decided to
do a python project for devops engineers
so the reason why I'm doing this video
is many of the subscribers or many of
the aspiring devops Engineers they have
learned python or they are learning
python but the major problem is that
they don't have a very good reference of
python projects for devops engineers now
you might Learn Python but to Showcase
your experience in your resume you need
to show that you have implemented some
project in devops or when your
interviewer asks you tell me an example
of how you used python you cannot just
say that I wrote some random scripts but
instead you should be able to tell that
I have used python in this real-time
implementation or I've created a project
using Python and this is the end goal of
the project and this is the end to end
architecture of the project so that is
what I am going to explain today in this
video like the previous videos with
respect to CI CD and cell screen live
projects in this video you are going to
learn about the summary of the project
you are going to understand the high
level design of the project I am going
to talk about the project goals that
means what are you going to achieve
through this project we'll talk about
implementation how to implement this
project and demo would be part two
because you know I want everyone to
understand this theory part you know
digest this and you know probably
tomorrow or Monday I'm going to come up
with the demo part as well but overall
what is the project that we are going to
learn today I have given the project
name as AWS ninja so now this is a name
that I have given and end of the video
you will understand why do I call it as
AWS ninja and this is a project powered
by python because
this project is going to be implemented
end to end in Python
now let's try to understand what is AWS
Ninja
so as a devops engineer now don't try to
copy this or you know don't try to take
a screenshot of this don't worry I have
everything in a GitHub repository I'm
going to share you the details of GitHub
repository the link will also be in the
description so don't worry about that
end of the video you will get all the
notes all the uh you know details that
you can put in your resume
so as a devops engineer one of your
primary responsibility is that you know
you need to maintain your Cloud
infrastructure so in the last video I
told you how to create the cloud
infrastructure using shell scripts right
we use the AWS CLI and we created a lot
of cloud infrastructure and we created a
project out of it as well but once the
project is created now let's say that
there is a
developer or there is a QE engineer you
have allocated them with proper IM rules
and let's say one of the developer is
responsible or you know they have
permissions to create a
S3 bucket just for an example and you
know there are a lot of S3 buckets that
are getting created in your organization
but they are not getting created with
versioning so S3 does not have
versioning by default now what happens
if some information is lost or let's say
ignore about versioning let's say these
S3 buckets are created unencrypted right
now S3 buckets are encrypted by default
but previously uh S3 buckets all the S3
buckets were not encrypted by default
so let's say any of these things is
happening and as a devops engineer it is
it is your responsible to take care of
governance of your AWS
account what is governance so governance
is nothing but if you look at this
example here there is a actor no actor
is not any movie actor but actor is
someone who is trying to create an
action so let's say uh there is a
developer or QE engineer and this
developer or QE engineer tries to create
some resource on AWS so it can be an ec2
instance it can be uh you know anything
like AWS EFS or it can be anything like
RDS or it can be something like IM okay
so he's trying to create something he or
she is trying to create something and
there are specific rules for your
organization what does these rules means
so as a organization or as a startup or
MNC you have some complaints for your
organization what is compliance
compliance is a set defined rules to
make sure that everybody is following
certain standard to make sure that there
is no security impact to make sure that
everybody is on the same page
so one of the rules one of the
compliance rules for your organization
is any S3 bucket that is created should
have versioning by default or you know
there is a rule that someone is creating
RDS they have to create tags for the
ideas to ensure that you know the tax
represent which team has created this
RDS and you know in future if you want
to just get an data of RDS instances
created by a specific team you can use
this tags to pull the information for
some reason whenever this actor has
created a RDS instance or EFS let's say
uh this person has created EFS
without encryption or he created S3
bucket without versioning now what
happens on a high level is every AWS
resource okay every AWS resource tries
to send notifications to cloudwatch for
whatever event that has happened so most
of the people think that AWS cloudwatch
pulls the information from the resources
but it's not true AWS resources send
notification to AWS Cloud watch so I
don't have to explain AWS cloudwatch I
believe because cloudwatch is a resource
that completely takes care of monitoring
it can send out some events
notifications to your other AWS
resources
no let's not go into all of those things
but right now the scope of the project
someone has created AWS resources and
they have created this AWS resources
against the complaints of your
organization now as soon as it is
created if there is no devops
engineering team or you know there is no
this project called AWS ninja then what
happened someone has
broken or you know someone has misused a
creating of AWS resources against the
complaints of your organization so to
solve this problem as a devops engineer
what you can do is you can make use of
the cloud watch because cloudwatch is
getting the information of every
resource that is getting created Now
using Cloud watch you can send this
trigger so cloudwatch has the event
information cloudwatch can send some
triggers so you can send a trigger to
AWS Lambda function and in this AWS
Lambda function you can write your
Python scripts
okay not just the Python scripts and
most people think that uh if I'm using
AWS Lambda function I'll be writing only
a simple python script no that's not
true in AWS Lambda functions the main
advantage is that it's a serverless
computer so instead of writing python
functions or instead of Hosting your
python application somewhere else what
you can do is you can simply write your
python application in Lambda functions
and Lambda function because it's a
serverless compute it can start anytime
uh once the AWS cloudwatch is triggers
this Lambda function and using this
python function you can evaluate like
AWS cloudwatch will send the entire
information to python that is in Lambda
function so your Lambda Handler gets
triggered and in the Lambda Handler you
can write code to read this AWS
resources let's say you have one Lambda
function for EFS you have one Lambda
function for S3 bucket you have one
Lambda function for ec2 instances so
depending upon the cloud watch trigger
so you can inform Cloud watch which
Lambda function to trigger okay so your
Cloud watch will trigger that whenever a
EFS resource is created cloudwatch
triggered a EFS related Lambda function
and whenever a Lambda function is
triggered what would be the first first
function that gets triggered the Lambda
Handler now inside the Lambda Handler
inside your python code you can evaluate
or you can validate if the resource is
created according to the compliance of
your organization if all is okay then
your Lambda function can simply return
all okay you don't have to do anything
but if there are any changes that need
to be made then using this Lambda
function you can automatically correct
these things so let's say your RDS does
not have tags you can create tags so how
you create tags you can understand which
group does this actor belongs to right
you know his IM role you know his IM
user and you know you should probably
understand uh which group this IM user
belongs to and then you can attach
Stacks accordingly or let's say your EFS
is not encrypted then you can say that
in your Lambda functions that is in your
python code there is a default KMS you
can say that this is the default KMS and
whenever I find out that there is a EFS
without encryption I will attach this
KMS to it
or let's say there is a ec2 instance and
this ec2 instance is created with very
low configuration let's say this is
created with very less CPU very less
memory and as soon as it is created and
the application is hosted you notice
that the application is going down
because of this ec2 instance compute so
either you can do ec2 auto scaling but
using this project what you can also do
is you can ask your Cloud watch to send
notification or to send trigger whenever
the CPU or memory reached to a certain
threshold and this Lambda function can
automatically increment your ec2
instance compute or it can automatically
instance any uh increase anything
related to your ec2 instance so this is
the explanation of the project what you
are doing overall here you are doing the
governance of your AWS environment and
what is governance governance is
basically ensuring that everything in
your organization is correct every
resource that is created in your
organization is according to the
compliance of your organization that's
why this project is called as a ninja
who is ninja ninja is a person who
safeguards your entire organization
because these scripts are written in
Python I said powered by python now
as you understood the high level design
of it the reason why I started with the
high level design is because all of you
should understand what is this project
about then I can probably start with the
project summary so that I can make sure
that it is not going out of your head or
it is not going something like you know
uh I'm not able to understand anything
so that's why I started with the high
level design now let's take a look at
the project summary what did I say here
AWS ninja is a governance project where
you can change these words as well when
you try to put these things in your
resume you can say AWS ninja is a
compliance project you can say AWS ninja
is uh a gatekeeper project whatever you
would like to but in in my project
description what I'm saying is AWS ninja
						 summary:is a governance project that use Lambda
functions to optimize and manage AWS
resources right what exactly is it doing
it is managing the AWS resources
with AWS ninja you can easily go on your
AWS resources automate compliance checks
that's what I'm doing right so I have
automated the complaint sticks is the
compliance I mean is the resource
matching the complaints of the
organization I'm validating here in the
python code of the Lambda function if it
is matching then yes everything is good
do nothing if it is not matching then
yeah you have to make changes so that's
why I said automate complaint sticks and
enforce policies
by leveraging Lambda functions AWS ninja
enables you to ensure security
compliance and cost efficiency of your
AWS infrastructure so I have already
explained why security because
sorry if someone creates your AWS
resources without S3 bucket versioning
or someone creates with some you know
the resources are created without taking
care of security probably and I am this
person creates a im user in probably
that I am user is only restricted to uh
certain resources but still if the IM
user is created with privileges that may
affect the security of your organization
using this project and using this python
code in the Lambda function you can
correct it now why complaints complaints
because you are ensuring that complaints
of your organization is matched
then cost efficiency yeah when I
practically explain you about the demo
then you will even come to know about
the cost efficiency because like I can
give you a simple example but in the
demo part I can explain you much better
for the sake of understanding here using
this Lambda functions what you can do is
let's say there are this EFS resource
that is created and but nobody is using
it for 30 days nobody is using it for 60
days then why should this EFS be there
in your project and AWS is charging you
for that EFS instance so using this
Lambda functions you can also get the
timestamp and you can delete that if
nobody is using for past 30 days or past
60 days that's why I mentioned cost
efficiency as well
whether you are a small startup or you
are a large Enterprise AWS Ninja can
streamline your AWS governance and
improve the efficiency or operations of
your organization so this is the project
summary you can use this as it is in
your resume as well but make sure if you
try to put this in your resume you have
implemented this by your own like
interviewer might ask you or ask you
some questions like you know how does
the Lambda function get triggered from
cloudwatch or interviewer might ask you
what exactly have you written in the
Lambda Handler function so definitely
I'll explain you that in the demo part
uh
yeah next is what are the project goals
so again
you might explain this entire thing to
the interviewer like you might also
implement it by yourself but it is very
important to write down the project
goals so when you write down the project
goals you can also explain your
interviewer at the end of this
implementation we were able to achieve
these things and because of these things
my organization has got a great benefit
now what are the things what can be
these project goals the project goals
can be the very first thing
fix not properly secured S3 buckets I
have already explained you right let's
say uh there is versioning that is not
enabled or previously S3 buckets can
also be created without encryption right
now they are by default encrypted but
yeah either of these two things one is
versioning and other is security second
fixed not optimized ec2 instances that's
what I mentioned right let's say the cc2
instances are created with very less CPU
and memory now you know that the your
organization applications at least
require two CPU and 8GB memory but for
example this person has created an ec2
instance with one CPU and one memory so
you know definitely that this ec2
instances are going to go down so you
can automatically optimize or you know
you can automatically correct this ec2
instances using the Lambda functions
fix not automated backups and Disaster
Recovery this is very very important I
don't have to even explain why backups
and Disaster Recovery is very important
and this backups and Disaster Recovery
can be with respect to anything it can
be with respect to EBS it can be with
respect to EFS S3 buckets anything
fix not automated routine tasks like you
know uh very simple routine as as a
devops engineer that you are managing
every day if they are not automated you
can automate them using the Lambda
function finally fix IM permissions and
rules properly that's what I mentioned
right let's say this person has created
a im user here or he has created I am
policy or IM role
which is you know using this Lambda
function when you try to dig down the
policy rules you might find it like oh
okay there is something that is very
high here the Privileges are very high
as an organization we want to ensure
that there is zero privilege that is in
uh
implemented in my organization so using
this Lambda function you can always
evaluate what are the IM permissions
that are granted to a specific role so
using this Lambda functions you can take
the necessary action now you can achieve
these things when this project becomes
very stable like right now if you try to
achieve this entire thing using the
project or the project goals it will be
very difficult because you just started
implementing it so that's why what you
need to explain is we have done all of
these things like all of the project
goals have been implemented and we have
reached all of the project goals within
six months or let's say that we have
implemented this project uh one year ago
and from last one year we are enhancing
this project we are improving this
project and right now the project is in
the stable State and you as a devops
engineer has taken the responsibility of
Designing the project and implementing
the project if you are a senior devops
engineer or if you are a junior devops
engineer you can say that I have taken
part in the project and I have
implemented some key portions of this
project this is how you can explain
so if you want me to do a practical uh
demo or if you want me to explain with
one scenario let's say I can take uh ec2
instance or I can take EFS or I can take
EBS or we can also take a S3 bucket that
is not a version and using this example
project and using the Lambda functions I
can show you how cloudwatch will send a
trigger to Lambda functions and how
Lambda functions can automatically fix
this resources now after doing that you
can also try to implement by yourself
like let's say if you are very
comfortable python you can try it today
as well like try to implement this
entire project today but at least one
thing that you have to do after watching
this video is try to understand this
entire project and try to
write down the project summary project
goals by yourself and end of the day if
you want to post it in LinkedIn you can
feel free to post that in LinkedIn I
don't mind but make sure that whenever
you are posting it please give the
proper credits to The Channel or you can
also tag me on LinkedIn because it takes
a huge effort for me to create all of
these things and end of the day if you
are not giving credit to the video or if
you're not giving credit to the
architecture design then yeah yeah okay
so this is the GitHub repository I was
talking about uh devops project ideas I
am viramala slash devops project ideas
and I have everything here like high
level design is here project scope is
here uh project summary is here so you
don't have to copy paste these slides or
you don't have to use some fancy tools
to get this information from the slides
it is already available in this GitHub
repository you can find the link in
description
finally if you haven't subscribed to my
Channel please do subscribe to the
channel because it takes a lot of time
to make these videos it takes a lot of
time to write down all of these things
so all that I expect is everyone to
subscribe my channel thank you so much
if you want me to do the Practical
implementation with one of the example I
cannot do with all of them I can show
you how one of these things can be
implemented using Python and Lambda
functions I can do it but please put the
feedback in the comment section thank
you so much for watching the video I'll
see you all in the next video take care
byehello everyone my name is Abhishek and
welcome back to my channel so today's
video is a python project for devops
engineers you can use this project in
your resumes you can use this project
for explaining to the interviewer when
they ask you about practical knowledge
of python and how did you use Python for
your Cloud infrastructure or AWS
environment now what are we waiting for
let's quickly jump onto the video and
understand what is this project and what
is the project description so last to
last week I shared the project idea it
is called as AWS ninja I give this word
I gave this name to the project you can
change the name as per your requirement
it does not matter that it has to be AWS
ninja or something else now what is the
project description I will give you a
very basic example before I jump on to
explaining the description so as a cloud
engineer it is or as a devops engineer
it is one of your goals or it is one of
your thumb uh you know one of your job
responsibilities to maintain the
infrastructure according to the
complaints of the organizational
now it might be complicated I'll give
you very very Layman terminology let's
say someone creates a EBS volume of type
gp2 so in ABS you can create volume of
type gp2 or gp3 let's say someone has
created an EPS volume of type gp2 but
your organization wants all the EVS
volumes to be of type gp3 why because
gp3 has better performance when compared
to gp2 it's it's quite fast and there
are other things so that's why one of
the organizational rules is that anyone
who creates EBS volume on the AWS
accounts it should be of type gp3 but
how do you do that let's say you create
documents to it you share the knowledge
you uh you know explain everyone that
EBS volume should be of type gp3 but
still someone who is joining new or
unexpectedly Unfortunately they have
created EBS volume of gp2 now how do you
handle this scenario because you are the
cloud Engineers you are responsible for
it so what you can do is you can use
this project that I am going to explain
and you can convert this EBS of type gp2
automatically to EBS of type gp3 now
this is just an example the options for
this are endless you can even consider
this as an ec2 instance let's say
someone creates an ec2 instance with 100
GB CPU sorry 100 GB RAM and 100 CPU
as a cloud Engineers you should restrict
such actions right what if there are 10
Engineers who keep on creating ec2
instances with large resources then you
know your organization is affected by
these uh developers or these persons who
are creating this infrastructure so to
block these things or to ensure such
things are not uh taken place you need
to use this project and this project is
basically ensuring that you maintain the
AWS infrastructure or Cloud
infrastructure according to the
complaints of your organization
so that's what I mentioned here as a
cloud engineering team we can take care
of new uh sorry we can take care of
we sorry we take care of AWS environment
and make sure it is in compliance with
the organizational policies
for example we trigger a Lambda function
when AWS elastic blocks store that is
EBS volume is created what we do is we
verify if it is of type gp3 if it is of
not type gp3 then we automatically
convert the gp2 type to gp3 type and how
do you do that we use AWS cloudwatch in
combination with AWS Lambda functions
and inside the AWS Lambda functions we
use python as scripting language okay so
this is the big picture and now let's
jump on to understand how to do this
what are things required to implement it
and we will also do the same example
that I have shown you right I will try
to keep this video as informative as
possible at the same time I will try to
restrict the time as well because many
people would engage if the video is
small sweet and informative
no problem so firstly let's start
creating an EBS volume of type gp2 and
let's see how it gets converted
automatically to gp3 but before that we
need to do some prerequisites that is we
need to create a Lambda function we need
to create AWS cloudwatch and integrate
both AWS cloudwatch and AWS Lambda
function so that Lambda function gets
triggered by cloudwatch when EBS volume
is created
so I hope you understood the project
what am I going to demonstrate and what
is your role as Cloud engineers and
similarly you can try thinking different
options like I gave example of EBS I
also gave example of ec2 you can think
of S3 buckets you can think of RDS you
can think of kubernetes that is eks n
number of possibilities and this project
scope is endless because number of
resources on AWS number of policies that
your organization can build around that
resources the compliance rules that you
can that your organization can build as
Cloud Engineers you have to take care of
ensuring that every resource is
following or is according to the
complaints now without wasting any time
what I'll do first is this is my AWS
console I hope you are seeing the right
screen perfect you are seeing the right
screen
now what I'll do is I'll start with a
basic Lambda function I'll not write the
Lambda function immediately but I will
just what I'll do is I'll just create a
basic Lambda function okay
so take a new tab
and
search for Lambda
so this is the Lambda function here and
let's create a new Lambda function
okay
perfect create function
what we will do is we will call this
Lambda function as EBS
volume
check
okay so I'll just call it as EBS volume
check because we are verifying the EBS
volume then let's use python 3.
I'll not change any of these things
let's use the default execution role
itself or if you want I can also create
an new AWS role okay but for the purpose
of keeping the video very simple let's
use the basic Lambda function that is
created here and what I'll do is I'll
update the permissions of this role
because there are many beginners who are
watching this video I don't want to
confuse them by creating lot of
resources okay
but if you are already uh well versed
with AWS or you have acquaintance with
acquaintance with AWS what you can do is
instead of using this default Lambda
rule that AWS creates for the Lambda
function you can also use a im role by
creating IM rule by yourself I will tell
you what permissions are required
okay so this is a very basic Lambda
function that AWS has given us okay so
there is no code related there is no
python even a single line of python code
is not available here related to our
function because this is a default value
so if if you check this function can be
executed like you can click on test and
provide uh the event name as test event
click on Save and once you run this you
will notice that the Lambda function is
running so this is a basic check that
you have to do to ensure that your
Lambda function is working
perfect now let's go to cloudwatch
so search for cloud watch
you have to be very clear with what you
are doing only then you will understand
this entire process that's why I
initially try to explain about the
project
so we are going to the AWS cloudwatch
and what I will do is I will configure a
rule in AWS cloudwatch which will
trigger the Lambda function
okay so what we need to do here is go to
this section here under the events you
will see something called as rules click
on that and after that click on create
rule because we need to create a new
role sorry new rule and select the name
of the service so in my case the name of
the service is
let's see if we have EBS if not we can
go with ec2
perfect what is the event type so the
event type is volume creation right so
let's put it as EBS volume notification
do you want to specify any specific
event like for example do you want to
specify creation of volume yes because
the scope of my project is only for
creation of volume always ensure that
whenever you create any resource in AWS
the thing that you have to keep in mind
is least privilege or zero privilege
that means you need to try to restrict
the actions you need to try to restrict
the permissions everything to the extent
of your project if you go beyond that
then you are creating a security
violation
any volume Arn or specific volume Arn
right now I don't know the Arn of the
EBS volume that is getting created
that's going to be created and this
project should have any volume Arn
because any volume that is created your
Cloud watch and the Lambda function
should monitor it so that's why I'll
keep it as any volume
now what you can do is you can also add
a Target okay so what is the target EBS
volume check the function that I have
written the Lambda function that we
wrote is the
uh how do I say that is the Lambda
function
again do you want to configure any
versions for your Lambda function or
anything etcetera no I don't want to so
I'm fine with it
and I don't want to add any additional
Target there is only one target for my
function okay so let's click on
configure details now what is the name
of your rule definition let's give the
same name called EBS
volume
check
description we can give the same project
description okay in your organization it
is very important to provide the
descriptions okay so for now I'm
providing the same project description
but you need to modify accordingly
Okay now click on create rule
I hope it is clear on what we have done
till now all that we did is we have
configured the Lambda function sorry AWS
Cloud watch to trigger the Lambda
function when there is a volume creation
event now before I write the code for
verifying the gp2 and converting it into
gp3 what I need to check is I need to
verify if my cloud watch is able to
access the Lambda functions right so for
that I can do a dummy run
okay what I'll do is I'll create a dummy
Lambda function uh I'll create a dummy
EBS volume
go to your ec2 dashboard volumes are
under ec2 dashboard see you can find
something called elastic Block store
move to volumes and inside the I mean
here what you will do is you can create
a volume uh looks like I already have a
volume let me delete that
make sure you delete the volumes after
you create
um okay something is going wrong here
perfect delete volume
I have deleted the volume now let's
create a new volume and the expectation
is the Lambda function should get
triggered and see here by default the
type is of gp2
but right now your Lambda function does
not have that logic to convert it to
type gp3 because we have not written any
python code but if you look here the
type is gp2 this is the default type
awesome now let's just queue it a minute
because Lambda function has to trigger
the sorry cloudwatch has to trigger the
Lambda function so
now let's go to the log groups
and see if the Lambda function is
triggered and executed
it's just taking a minute
perfect now
you will notice
the log group for Lambda functions and
specifically to your Lambda function
okay I think there is some delay just a
second
okay so uh there was some delay but uh
if you go to the cloudwatch log groups
now I can see that uh you know there is
a log stream here there is a log group
here if we go to this log group let us
see what is the latest log group okay so
this is the latest log group and if I go
into this one I will notice that there
is a Lambda function that got triggered
okay so this is the Lambda function that
got triggered and what does it do is it
is a very basic Lambda function and it
does not execute anything related to
your EBS volumes but this is just for
verification that my cloud watch when
there is a EBS volume that gets created
triggers the Lambda function okay
nothing more than that
so my verification the basic
verification has passed now what I'll do
is I will go and write the python code
for converting the EBS volume of type EP
sorry of type gp2 to type gp3
so let's do that here
the very first thing that you need to do
is understand how Lambda functions works
so in Lambda function there is a default
function called Lambda Handler that is
the one that gets triggered or that's
the one that gets executed as soon as
your Lambda function is called now you
can modify this you can change this
Lambda Handler in the configuration and
you can provide any custom name and what
is this event and what is this context
so event and context are provided by the
invoking uh function invoking resource
now cloudwatch is invoking this Lambda
function so the event is the cloud watch
event okay so this Json event is
basically a Json is provided by
cloudwatch and what do we have inside
this event you can verify that what you
can do is just provide this detail here
called print event
okay so this is a print event for you to
understand what is the event okay what
is this Json that
uh cloudwatch is providing to the Lambda
function when EBS is created okay so
just click on deploy every time you make
a change it is recommended to uh deploy
the new change or use Ctrl s
now test it
perfect Lambda function is in good shape
now test it from the cloud watch so that
you understand what is this event okay
so again what you need to do for that is
remove this ebase volume that you have
created and create a new one because you
are cloudwatch triggers the Lambda
function only when a EBS volume is
created
so delete the volume
and let me create a new volume
always make sure you are deleting the
volumes
so now again a new volume is created and
wait for a minute your log group will be
updated and but this time in the log
group you will get the full details of
your EBS volume that is created and this
full full details are sent to the Lambda
function as a cloud engineer you will
use this even details and you will write
the logic in your python code for
handling the event and updating the
ebase volume of type gp3 so we are just
five minutes away to complete this
project stay tuned
this is a log group now you will notice
that there is a new log stream okay so
this is the latest one that I have and
if I go into this one
see you have the complete details of the
EBS volume that is created you can
search uh so this is the volume name
that cloudwatch log groups tells us let
us verify
perfect you can verify that the volume
is same so this is the Json data now
what is this Json data let us
investigate for that what you need to do
is take a online Json formatter
any Json formatter is fine uh
just search for Json formatter
okay so I've just opened a Json
formatter provide the details here
process and you will get the entire
details so this is the same details that
cloudwatch is providing to the Lambda
function okay so you can assume that
let's say you are a beginner to python
you can assume that this function is
translated something into this okay
event is equals to
the Json data
now this is just for your understanding
okay you don't have to put this thing
but
just understand that this is how this
function is converted okay the event is
populated with this details so you don't
have to provide this thing now because
event is already provided by the AWS
Cloud watch
so now what are these things inside it
which you can use the only thing that I
would need is the name or the ID of the
Lambda function okay so this is
something that I need so that I can
convert this volume ID or the volume of
this ID to type gp3 now how do I extract
this information okay firstly I think
most of you know that in Python the most
popular package that you would use is
boto 3. now I will use boto3 the python
module to convert this volume to type
gp3 but before that I have to extract
this one so for extraction I will write
a new python function okay so I'll just
call it as uh very simply
let's call it as python function of name
what name should we provide let's
provide the name as
extract volume ID
okay you can provide any name just take
name as input
and now what I'll do is inside this Iwill write the python code related to
this one
okay so I already have this handy so
that we don't waste a lot of time
so I just change the name of it to get
volume ID from Arn okay so what we are
doing here is we are firstly taking
extracting this entire arm and from this
Arn what I am doing is I am extracting
this volume ID okay now how do I extract
this one you know that this is a Json
information right so why I put this one
here we don't need this one but just for
your understanding I have this one here
but once we complete the function I'll
remove this block because it's very
difficult to go back to the log group
and always show you this information
what I did is I have this information
here but once the function is done I'll
remove it
so get volume ID from arm we are taking
the volume Arn as an input that means we
are taking this as input but to take
this as input you have to pass this Arn
to the function right to pass this AR
into the function firstly what I'll do
is I'll parse this Json how do you parse
the Json in Python all that you need to
do is uh let's say let's call this as
volume Arn
okay to parse this what I can do is
simply
volume arm is equals to event
of what is the function here resources
of 0. okay why I am doing 0 because I
just want the first entry that's it
nothing more than that right I am just
taking the first entry and I'm calling
it as volume Arn or you can also call it
as resource Arn or whatever you would
like to now I have this information
right now I will pass this volume Arn to
this function and retrieve the volume ID
okay so for that what I can do is call
this function
uh let me call this as
volume underscore ID and I will pass
this information to the function
and let's pass this one called volume
Arn so now you will get the volume ID
okay so you have the volume ID what you
need to do next is use this python
module called moto3 and convert this
thing the
volume of type gp2 to type gp3 so for
that you need to again go to your
browser and search for go23
modify
volume okay because you are trying to
modify the volume go to the python
documentation I mean the Border 3
documentation and you have the very
clear instructions here just copy this
instruction
where is this here perfect
and what I'll do is I'll just paste it
here
format it
do I need this
no I don't want to talk anything related
to dry run do I need the volume ID
absolutely yes
just copy the volume ID here
do I need the size right now I'm not
bothered about it what is the volume
type that you need I need the volume
type as gp3 okay so what you are doing
here you are using the Lambda function
sorry you are using the Moto 3 you
haven't created the client don't worry
I'll tell you how to create the client
but I am using the modify volume
function and I am trying to convert the
volume of this ID to type gp3 I don't
want any of these things so let me
remove and finally I just have to create
a client so what is this client so
client in Moto 3 is nothing but like
boto3 can handle all the AWS resources
or most of the AWS resources but you
want to use a client for your specific
resource okay so what I'll do for that
is again you can go to the boto3
documentation you have to understand
that which type of resource is it so EBS
basically falls under ec2 so I am going
to create ec2 client where I call it
Auto 3
dot client
ec2
okay now if you are dealing with some
other resource then let's say you are
dealing with S3 then it will be S3
client if you are dealing with something
else then you have to create that
something else client and that's it we
are technically done now let me try to
remove this thing
I'll try to keep this python function as
minimalistic as possible I don't want to
use event okay now
remove this perfect if you want to add
comments then it is very good you can
add n number of comments
so that your function is much more
readable but let's try to understand
what I've written here one is import
Json is not required because we are not
doing any Json related formatting
I have imported the boto3 functionality
I have imported the Border 3 module and
this is the get volume ID from arm this
is the volume Aaron that I am trying to
sorry the volume ID that I am trying to
retrieve from the volume arm so how am I
doing it basically I am using this
function called get volume ID from Arn
and I'm passing the volume Arn so how
did I pass the volume Arn I read the
event from the log group I use the Json
formatter I understood where the volume
ID is and I got that basic information
after that you can basically use the
boto3 client for ec2 and modify the
volume now as soon as I deploy it and
you know if I create a test volume it
should work fine but one thing that is
left is you have to Grant the
permissions to this IM role
why because the IM role will not have
permissions to access the EBS resource
so for that what I'll do is quickly go
to
somewhere here what you can do is
duplicate this tab
and go to IM
some of every time I open a tab it gets
slow but that's fine let's try one more
time
cool I am
oh sorry I need to search here not there
my bag
so go to IM and there will be an
existing role for your EBS I just try to
add or attach it with a policy to handle
the EPS now that will be your final step
after that I'll show you practically we
are just two minutes away you will see
that the volume is converted to type gp3
sorry again it's bit slow
click on the three roles you will find
the role for yourself
this is the role EBS volume check hyphen
roll hyphen this random string that
is prefixed sorry that is suffixed
add permissions
attach policy or create inline policy
you should go with create inline policy
um what happened here
so I think it's getting refreshed
okay choose the service so the service
should be of type
ec2 as you already know
okay so what exactly in ec2 are you
looking for okay so in ec2 there will be
several actions and you should find the
correct action like I always tell you
don't provide permissions that are not
required just for the demo you can do
that but in your organization when you
are doing it do not provide more
permissions okay so select the ec2 that
is of Services of type ec2 and then what
you will do is go with the action
for now because of the demo you can just
select all ec2 actions but go with
expand all and select the permissions
that are required in your case you will
mostly need permissions related to list
volume describe volume and then you will
need permissions related to
um just few things uh probably you don't
even have to describe the volume but you
have to just modify the volume so these
are the permissions that you will
require
let me review the policy
and
there is some error the policy contains
an error okay let's see what it is
okay uh I think it's better to restrict
uh the permissions related to volume so
now I choose uh volume here and let's
provide the permissions that are
required uh describe volume I don't
think even describe is required but
let's provide the permissions later to
describe and
modify volume okay because we are
basically doing the modify volume
and do you want to provide anything
related to a resource arm no I want to
do it for all the resources because my
function has to deal with all the
resources now finally review the policy
and just create the policy okay
let's provide the same name EBS
volume check
create policy
foreign
now get let's get ready for the final
step where I will delete this volume
create a new volume and we will see that
the volume is converted to type gp3
let's delete this volume
perfect create the volume
I'm not going to change anything click
on the create volume if the Lambda
function is successfully executed we
will notice that the type is converted
to gp3 if it is not executed then let's
try to see what is the error and let's
try to fix it
okay it's still of type gp3
let us see if it is converted to type of
gp3 if not like I told you let's try to
fix it
final check
I'm hoping it will pass
let's see the volume type
okay it's still gp2 let's go to the
cloud watch logs and see what has
happened okay so this is a cloud watch
logs let's go to the log groups one more
time and let's see the latest log group
if there is any issue we should be able
to fix it
this is a volume volume group
and this is the latest volume stream
this is updated right now
let's open the volume group
see there is an error here it says
resources is not defined in traceback
okay so what is this resources let's see
okay it clearly says that
in line number 13 my Lambda function is
not working perfect there is no problem
let's go to the Lambda function
and let's try to fix it what is line
number 13 here it says event resources
ah okay so if you check the event uh I
have somewhere this is the Json right
since
inside the event you have something
called as resources
am I wrong with it somewhere
okay I think I got it
should be inside the single quotes right
so see we do kind of silly mistakes now
let's try to deploy it one more time and
it's time for one more attempt where I
will delete this existing volume and
recreate a new one
delete
okay let's create a new volume create
volume one more time we are giving our
second attempt and hopefully this time
it will pass
again if it doesn't pass you don't have
to worry just like I showed you go to
the log group try to identify the error
it's always good if we fail in the demo
because people who are watching the
video they'll be able to understand
where exactly is the implementation
going wrong and how to fix it
so I refreshed it now let us see if the
volume is of type gp3
loading volumes
okay it's still on gp2 probably we did
one more mistake
this is the latest one let us see where
did we go wrong again
name client is not defined okay so it
says that the client dot ah okay
because I was doing it live I just did
some very simple mistakes it should be
EC to underscore client because we have
defined it as ec2 and this time I'm very
sure it will pass uh let's delete this
one
foreign
attempt
I hope that subscribers who are watching
this or the viewers you are learning
from the mistakes that I am doing
now I have created the volume and this
time I'm pretty sure if I refresh this
this should be of type gp3
final check
gp3
you can play this video at 2x speed so
that you don't get bored while watching
it but we are doing a practical
implementation and it is very good
always to learn from the mistakes
okay still GP
very strange
is it that it did not get refreshed or
ah
Okay so
ec2 client right
what is the mistake it says here
why did I provide EC client
is it not easy to underscore client
probably it's not well deployed line
number
what does it say
Trace line number 18
ECC client no I think uh it's not well
read so let's try to redeploy this
ec2 underscore client perfect I think
it's issue with caching
not from our side
okay now I hope finally it will pass
uh last time was a caching issue I don't
think it's issue from RN but let's try
to see one more time
so I don't want to edit this part
because people who are watching it you
can learn from the mistakes so I'm not
interested in editing and I'll post it
as is without making any changes
so if again it is not converted to type
gp3 probably there is some uh issue with
yeah perfect
gp3 so this is it and I hope you like
the demonstration where we have seen how
to use this function how to use this
project called AWS ninja like I told you
I'll put this entire thing in the
description so that you can follow the
video thank you so much for watching the
video I hope you found this useful and
the demo part which failed initially
learned from that mistakes and
try to implement this with multiple
examples I'll see in the next video If
you haven't subscribed to our Channel
please subscribe to the channel take
care everyone bye						
																													  
																													  AWS Ninja
Project Summary
"AWS Ninja" is a governance project that uses Lambda functions to optimize and manage AWS resources. With AWS Ninja, you can easily govern your AWS resources, automate compliance checks, and enforce policies. By leveraging Lambda functions, AWS Ninja enables you to ensure the security, compliance, and cost-efficiency of your AWS infrastructure. Whether you're a small startup or a large enterprise, AWS Ninja can help you streamline your AWS governance and improve your operations.

Project Scope
Fix not properly secured S3 buckets: Lambda functions can be used to monitor S3 bucket access and enforce security policies, such as preventing public access, encrypting data at rest, and logging all access activity.

Fix not optimized EC2 instances: Lambda functions can be used to monitor CPU utilization and other metrics of your EC2 instances, and automatically adjust the instance size or capacity based on the workload. This can help optimize performance and reduce costs.

Fix not automated backups and disaster recovery: Lambda functions can be used to schedule backups and automate disaster recovery processes, such as copying data to a backup S3 bucket or launching a new EC2 instance in case of a failure.

Fix not automated routine tasks: Lambda functions can be used to automate routine tasks, such as database backups, log analysis, and file processing. This can help reduce manual effort and improve efficiency.

Fix IAM permissions and roles properly: Lambda functions can be used to enforce IAM policies and roles, such as granting least privilege access and rotating access keys. This can help improve security and compliance.



'''
project name AWS ninja :
Flow digram:
A devops engineer > creates > an AWS Service > Alarms > AWS Cloudwatch > Trigers spec > Lambda Functions > validate againt complience > 1. make changes > an AWS Service 
                                                                                                                                      > 2. all ok > DO NOTHING              '''
